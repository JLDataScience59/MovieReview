# ğŸ¯ Projet Deep Learning - Word2Vec & Streamlit

## ğŸ“ Objectif

Ce projet a pour but de mettre en Å“uvre un projet complet de **Deep Learning** et de le prÃ©senter de maniÃ¨re interactive grÃ¢ce Ã  **Streamlit**.

Lâ€™objectif principal est de :
- Construire un modÃ¨le **Word2Vec** (word embeddings),
- L'entraÃ®ner sur un corpus de critiques de films,
- Sauvegarder le modÃ¨le (`.h5`),
- Visualiser et explorer les rÃ©sultats Ã  travers une application **Streamlit** dÃ©ployÃ©e.

## ğŸ“ Organisation du projet

```graphql
.
â”œâ”€â”€ app/                  # Application Streamlit (app.py)
â”œâ”€â”€ models/               # ModÃ¨le entraÃ®nÃ© et tokenizer (fichiers suivis avec Git LFS)
â”œâ”€â”€ notebooks/            # Notebook d'entraÃ®nement du modÃ¨le Word2Vec
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ .gitattributes        # Suivi Git LFS pour le modÃ¨le
â””â”€â”€ README.md             # Ce fichier
```

## ğŸ’¡ Environnement requis

- Python 3.10
- Si tu utilises conda, tu peux crÃ©er un environnement comme suit :

```bash
conda create -n movie_review_env python=3.10
conda activate movie_review_env
pip install -r requirements.txt
```

### requirements.txt

Ce fichier liste les packages compatibles avec mon code et mon environnement :

```txt
streamlit==1.35.0
tensorflow==2.19.0
scikit-learn==1.4.1
numpy==1.24.4
pandas==2.1.4
nltk==3.8.1
```
âš ï¸ Remarque : tensorflow==2.19.0 car câ€™est celle que j'utilise. Si tu veux Ãªtre compatible avec tensorflow-cpu, tu peux prÃ©ciser :

```txt
tensorflow-cpu==2.19.0
```

Mais ne mets pas les deux en mÃªme temps (tensorflow et tensorflow-cpu sont mutuellement exclus).


## ğŸ§  DonnÃ©es

Le jeu de donnÃ©es comprend **25 000 critiques de films** en anglais. Ces critiques serviront Ã  entraÃ®ner le modÃ¨le Word2Vec pour apprendre des reprÃ©sentations vectorielles du langage (embeddings).
âš ï¸ Ce fichier nâ€™est pas stockÃ© dans le dÃ©pÃ´t pour ne pas alourdir le repo. Il est Ã  tÃ©lÃ©charger manuellement pour lâ€™entraÃ®nement ici : **[lien](https://train-exo.s3.eu-west-1.amazonaws.com/2317/MovieReview.csv)**

## ğŸ§ª EntraÃ®nement du modÃ¨le Word2Vec

Un notebook d'entraÃ®nement est disponible dans notebooks/, contenant :
- Le nettoyage des donnÃ©es textuelles,
- La tokenisation et la construction du vocabulaire,
- Lâ€™entraÃ®nement du modÃ¨le de type skip-gram via Keras,
- La sauvegarde des artefacts :
    - word2vec.h5 (modÃ¨le Keras),
    - tokenizer.pkl (tokenizer TensorFlow).

## ğŸš€ Lancement du projet

### 1. Cloner le dÃ©pÃ´t

```bash
git clone <url_du_repo>
cd <nom_du_projet>
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```
### 3. Lancer l'application Streamlit

```bash
cd app
streamlit run app.py
```

## Suivi des fichiers .h5 avec Git LFS

Ce projet utilise **Git LFS** pour suivre les fichiers de modÃ¨les volumineux :

```bash
git lfs install
git lfs track "*.h5"
git add .gitattributes
```

Le fichier `.gitattributes` contient dÃ©jÃ  les rÃ¨gles nÃ©cessaires.

## Technologies utilisÃ©es

- Python 3.x
- TensorFlow / Keras
- NLTK
- Gensim (Word2Vec)
- Pandas / NumPy
- Streamlit
- Git / Git LFS

## Auteur

Projet rÃ©alisÃ© dans le cadre du module Deep Learning de la formation **[Data-Scientist](https://datascientest.com/formation-data-scientist)** de l'organisme de formation **[DataScientest](https://datascientest.com)**
